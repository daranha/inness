{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "import random as rn\n",
    "import fiona\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint as rint\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def dist(i,j):\n",
    "    return np.sqrt( (i[0] - j[0])**2 + (i[1] - j[1])**2 )\n",
    "\n",
    "\n",
    "\n",
    "fp = fiona.open(\"/home/dario/Documentos/TR/redCDMX/VialidadOSM.shp\")\n",
    "calles = {}\n",
    "siq  = [u'highway', u'barrier', u'id', u'nombre', u'osm_id', u'other_tags', u'sentido', u'tipo', u'z_order']\n",
    "for feat in fp:\n",
    "    calles[ feat['id'] ] = {}\n",
    "    calles[ feat['id'] ]['type'] = feat['geometry']['type']\n",
    "    calles[ feat['id'] ]['coords'] = feat['geometry']['coordinates']\n",
    "    for key, val in feat['properties'].items():\n",
    "        if key in siq:\n",
    "            calles[ feat['id'] ][key] = val\n",
    "            calles[ feat['id'] ][key] = val\n",
    "\n",
    "            \n",
    "fp.close()            \n",
    "\n",
    "ntwk = pd.DataFrame(calles).transpose()\n",
    "ntwk.index = ntwk['id']\n",
    "ntwk = ntwk.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "i=0\n",
    "GN = nx.DiGraph(weighted=True)\n",
    "for row, col in ntwk.iterrows():\n",
    "    p = ntwk.loc[row]['coords']\n",
    "    lp = len(p)       \n",
    "    GN.add_path( p, name=ntwk.loc[row]['nombre'],\n",
    "                vialidad = ntwk.loc[row]['highway'], osm_id = ntwk.loc[row]['osm_id'],\n",
    "                sentido = ntwk.loc[row]['sentido'], tipo=ntwk.loc[row]['tipo']\n",
    "               )\n",
    "    i = lp + i\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "GG = nx.Graph(GN)\n",
    "gnc = sorted(nx.connected_components(GG), key = len, reverse=True)[0]\n",
    "gc = GN.subgraph(gnc)\n",
    "gnfc = sorted(nx.strongly_connected_components(GN), key = len, reverse=True)[0]\n",
    "gfc = GN.subgraph(gnfc)\n",
    "gfc1 = sorted(nx.strongly_connected_components(GN), key = len, reverse=True)[1]\n",
    "gf1 = GN.subgraph(gfc1)\n",
    "gfc = nx.DiGraph(gfc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ini = pd.read_csv('/home/dario/Escritorio/inness_csv/inness_fastest_I.csv')\n",
    "isi = pd.read_csv('/home/dario/Escritorio/inness_csv/inness_shortest_I.csv')\n",
    "#inr = pd.read_csv('/home/dario/Escritorio/inness_csv/inness_fastest_rho_A.csv')\n",
    "#isr = pd.read_csv('/home/dario/Escritorio/inness_csv/inness_shortest_rho_A.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3029\n",
      "3184\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "for xx in [ini, isi,]: # inr, isr]:\n",
    "    xx = xx.loc[ xx['city'] == 'Mexico_City'].drop('Unnamed: 0', axis=1)\n",
    "    print len(xx)\n",
    "    ls += [xx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0092021736562615825"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 19.4006, -99.1289\n",
    "b = 19.3914, -99.1291\n",
    "dist(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = ls[1]\n",
    "n4 = [x for x in gfc.nodes() if nx.degree(gfc, x) > 3]\n",
    "c = (19.432608, -99.133209)\n",
    "unk = 0.0092\n",
    "df['or'] = df.apply(lambda x:  (c[0] + x['radius']*unk*np.cos(np.radians(x['origin_angle'])),\n",
    "                    c[1] + x['radius']*unk*np.sin(np.radians(x['origin_angle']))), axis=int(1))\n",
    "df['de'] = df.apply(lambda x: (c[0] + x['radius']*unk*np.cos(np.radians(x['destination_angle'])),\n",
    "                    c[1] + x['radius']*unk*np.sin(np.radians(x['destination_angle']))), axis=int(1))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dif(a, b):\n",
    "    return np.abs(a[0]-b[0])+np.abs(a[1]-b[1])\n",
    "\n",
    "\n",
    "def closst(a):\n",
    "    dsts = [dist(a,x) for x in n4]\n",
    "    for y in n4:\n",
    "        if dist(a,y) == np.min(dsts):\n",
    "            return y\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closst(a):\n",
    "    d = dist(a, n4[49])\n",
    "    for y in n4:\n",
    "        if dist(a,y) < d:\n",
    "            d = dist(a,y)\n",
    "            z = y\n",
    "    return z\n",
    "\n",
    "\n",
    "def closst(a):\n",
    "    d = dist(a, n4[94])\n",
    "    for y in n4:\n",
    "        yy = (y[1], y[0])\n",
    "        if dist(a,yy) < d:\n",
    "            d = dist(a,yy)\n",
    "            z = y\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['oor'] = df.apply(lambda x: closst(x['or']), axis=int(1))\n",
    "df['dde'] = df.apply(lambda x: closst(x['de']), axis=int(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for edge in gfc.edges():\n",
    "    gfc[edge[0]][edge[1]]['dist'] = dist(*edge)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sp'] = df.apply(lambda x: nx.dijkstra_path(gfc, x['oor'], x['dde'], weight='dist'), axis=int(1))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dinn = {}\n",
    "dinn = dict.fromkeys(n4, 0.0)\n",
    "i= 0\n",
    "for xxx in list(df['sp']):\n",
    "    for yy in xxx:\n",
    "        dinn[yy] = df['normalized_inness']\n",
    "        \n",
    "        \n",
    "import pickle\n",
    "\n",
    "with open('/home/dario/Escritorio/dictinn.py', 'wb') as fp:\n",
    "    pickle.dump(dinn, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tam(n):\n",
    "    if n < 3:\n",
    "        return 1\n",
    "    elif n == 3:\n",
    "        return 1\n",
    "    elif n == 4:\n",
    "        return 2\n",
    "    elif n == 5: \n",
    "        return 3\n",
    "    elif n > 5:\n",
    "        return 3\n",
    "        \n",
    "        \n",
    "gradost['tam'] = gradost['gr'].apply(lambda l: tam(l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "##### ESTO LO METISTE A BORROMEO PARA OBTENER DICCIONARIOS CON CENTRALIDADES\n",
    "\n",
    "\n",
    "import random as rn\n",
    "import fiona\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint as rint\n",
    "import networkx as nx\n",
    "from heapq import heappush, heappop\n",
    "from itertools import count\n",
    "\n",
    "\n",
    "def dist(i,j):\n",
    "    return np.sqrt( (i[0] - j[0])**2 + (i[1] - j[1])**2 )\n",
    "\n",
    "\n",
    "# helpers for betweenness centrality\n",
    "\n",
    "def _single_source_shortest_path_basic(G, s):\n",
    "    S = []\n",
    "    P = {}\n",
    "    for v in G:\n",
    "        P[v] = []\n",
    "    sigma = dict.fromkeys(G, 0.0)    # sigma[v]=0 for v in G\n",
    "    D = {}\n",
    "    sigma[s] = 1.0\n",
    "    D[s] = 0\n",
    "    Q = [s]\n",
    "    while Q:   # use BFS to find shortest paths\n",
    "        v = Q.pop(0)\n",
    "        S.append(v)\n",
    "        Dv = D[v]\n",
    "        sigmav = sigma[v]\n",
    "        for w in G[v]:\n",
    "            if w not in D:\n",
    "                Q.append(w)\n",
    "                D[w] = Dv + 1\n",
    "            if D[w] == Dv + 1:   # this is a shortest path, count paths\n",
    "                sigma[w] += sigmav\n",
    "                P[w].append(v)  # predecessors\n",
    "    return S, P, sigma\n",
    "\n",
    "\n",
    "def _single_source_dijkstra_path_basic(G, s, weight='weight'):\n",
    "    # modified from Eppstein\n",
    "    S = []\n",
    "    P = {}\n",
    "#    nod = [x for x in G.nodes() if nx.degree(G,x) > 3]\n",
    "    for v in G:\n",
    "        P[v] = []\n",
    "    sigma = dict.fromkeys(G, 0.0)    # sigma[v]=0 for v in G\n",
    "    D = {}\n",
    "    sigma[s] = 1.0\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    seen = {s: 0}\n",
    "    c = count()\n",
    "    Q = []   # use Q as heap with (distance,node id) tuples\n",
    "    push(Q, (0, next(c), s, s))\n",
    "    while Q:\n",
    "        (dist, _, pred, v) = pop(Q)\n",
    "        if v in D:\n",
    "            continue  # already searched this node.\n",
    "        sigma[v] += sigma[pred]  # count paths\n",
    "        S.append(v)\n",
    "        D[v] = dist\n",
    "        for w, edgedata in G[v].items():\n",
    "            vw_dist = dist + edgedata.get(weight, 1)\n",
    "            if w not in D and (w not in seen or vw_dist < seen[w]):\n",
    "                seen[w] = vw_dist\n",
    "                push(Q, (vw_dist, next(c), v, w))\n",
    "                sigma[w] = 0.0\n",
    "                P[w] = [v]\n",
    "            elif vw_dist == seen[w]:  # handle equal paths\n",
    "                sigma[w] += sigma[v]\n",
    "                P[w].append(v)\n",
    "    return S, P, sigma\n",
    "\n",
    "\n",
    "def _accumulate_basic(betweenness, S, P, sigma, s):\n",
    "    delta = dict.fromkeys(S, 0)\n",
    "    while S:\n",
    "        w = S.pop()\n",
    "        coeff = (1.0 + delta[w]) / sigma[w]\n",
    "        for v in P[w]:\n",
    "            delta[v] += sigma[v] * coeff\n",
    "        if w != s:\n",
    "            betweenness[w] += delta[w]\n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _accumulate_endpoints(betweenness, S, P, sigma, s):\n",
    "    betweenness[s] += len(S) - 1\n",
    "    delta = dict.fromkeys(S, 0)\n",
    "    while S:\n",
    "        w = S.pop()\n",
    "        coeff = (1.0 + delta[w]) / sigma[w]\n",
    "        for v in P[w]:\n",
    "            delta[v] += sigma[v] * coeff\n",
    "        if w != s:\n",
    "            betweenness[w] += delta[w] + 1\n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _accumulate_edges(betweenness, S, P, sigma, s):\n",
    "    delta = dict.fromkeys(S, 0)\n",
    "    while S:\n",
    "        w = S.pop()\n",
    "        coeff = (1.0 + delta[w]) / sigma[w]\n",
    "        for v in P[w]:\n",
    "            c = sigma[v] * coeff\n",
    "            if (v, w) not in betweenness:\n",
    "                betweenness[(w, v)] += c\n",
    "            else:\n",
    "                betweenness[(v, w)] += c\n",
    "            delta[v] += c\n",
    "        if w != s:\n",
    "            betweenness[w] += delta[w]\n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _rescale(betweenness, n, normalized, directed=False, k=None):\n",
    "    if normalized is True:\n",
    "        if n <= 2:\n",
    "            scale = None  # no normalization b=0 for all nodes\n",
    "        else:\n",
    "            scale = 1.0 / ((n - 1) * (n - 2))\n",
    "    else:  # rescale by 2 for undirected graphs\n",
    "        if not directed:\n",
    "            scale = 1.0 / 2.0\n",
    "        else:\n",
    "            scale = None\n",
    "    if scale is not None:\n",
    "        if k is not None:\n",
    "            scale = scale * n / k\n",
    "        for v in betweenness:\n",
    "            betweenness[v] *= scale\n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def _rescale_e(betweenness, n, normalized, directed=False, k=None):\n",
    "    if normalized is True:\n",
    "        if n <= 1:\n",
    "            scale = None  # no normalization b=0 for all nodes\n",
    "        else:\n",
    "            scale = 1.0 / (n * (n - 1))\n",
    "    else:  # rescale by 2 for undirected graphs\n",
    "        if not directed:\n",
    "            scale = 1.0 / 2.0\n",
    "        else:\n",
    "            scale = None\n",
    "    if scale is not None:\n",
    "        if k is not None:\n",
    "            scale = scale * n / k\n",
    "        for v in betweenness:\n",
    "            betweenness[v] *= scale\n",
    "    return betweenness\n",
    "            \n",
    "fp = fiona.open(\"/home/dario/trafico/redCDMX/VialidadOSM.shp\")\n",
    "calles = {}\n",
    "siq  = [u'highway', u'barrier', u'id', u'nombre', u'osm_id', u'other_tags', u'sentido', u'tipo', u'z_order']\n",
    "for feat in fp:\n",
    "    calles[ feat['id'] ] = {}\n",
    "    calles[ feat['id'] ]['type'] = feat['geometry']['type']\n",
    "    calles[ feat['id'] ]['coords'] = feat['geometry']['coordinates']\n",
    "    for key, val in feat['properties'].items():\n",
    "        if key in siq:\n",
    "            calles[ feat['id'] ][key] = val\n",
    "            calles[ feat['id'] ][key] = val\n",
    "\n",
    "\n",
    "fp.close()\n",
    "\n",
    "ntwk = pd.DataFrame(calles).transpose()\n",
    "ntwk.index = ntwk['id']\n",
    "ntwk = ntwk.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "i=0\n",
    "GN = nx.DiGraph(weighted=True)\n",
    "for row, col in ntwk.iterrows():\n",
    "    p = ntwk.loc[row]['coords']\n",
    "    lp = len(p)\n",
    "    GN.add_path( p, name=ntwk.loc[row]['nombre'],\n",
    "                vialidad = ntwk.loc[row]['highway'], osm_id = ntwk.loc[row]['osm_id'],\n",
    "                sentido = ntwk.loc[row]['sentido'], tipo=ntwk.loc[row]['tipo']\n",
    "               )\n",
    "    i = lp + i\n",
    "    \n",
    "    \n",
    "gnfc = sorted(nx.strongly_connected_components(GN), key = len, reverse=True)[0]\n",
    "gfc = GN.subgraph(gnfc)\n",
    "for edge in gfc.edges():\n",
    "    gfc[edge[0]][edge[1]]['dist'] = dist(*edge)\n",
    "\n",
    "\n",
    "\n",
    "def betw_c(G, k=None, normalized=True, weight=None,\n",
    "                           endpoints=False,\n",
    "                           seed=None):\n",
    "    betweenness = dict.fromkeys(G, 0.0)  # b[v]=0 for v in G\n",
    "    if k is None:\n",
    "        nodes = G\n",
    "    else:\n",
    "        rn.seed(seed)\n",
    "        nodes = rn.sample([x for x in G.nodes() if nx.degree(GN,x) > 3], k)\n",
    "    aaa = len(nodes)\n",
    "    for s in nodes[]:\n",
    "        # single source shortest paths\n",
    "        if weight is None:  # use BFS\n",
    "            S, P, sigma = _single_source_shortest_path_basic(G, s)\n",
    "        else:  # use Dijkstra's algorithm\n",
    "            S, P, sigma = _single_source_dijkstra_path_basic(G, s, weight)\n",
    "        # accumulation\n",
    "        if endpoints:\n",
    "            betweenness = _accumulate_endpoints(betweenness, S, P, sigma, s)\n",
    "        else:\n",
    "            betweenness = _accumulate_basic(betweenness, S, P, sigma, s)\n",
    "    # rescaling\n",
    "    betweenness = _rescale(betweenness, len(G),\n",
    "                           normalized=normalized,\n",
    "                           directed=G.is_directed(),\n",
    "                           k=k)\n",
    "    return betweenness\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dbc = betw_c(gfc, k=20000, normalized=True, weight='dist',\n",
    "                           endpoints=False,\n",
    "                           seed=None)\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('dic_betw_cent3.py', 'wb') as fp:\n",
    "    pickle.dump(dbc, fp)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.DataFrame(dbc)\n",
    "    df.to_csv('dic_betw_cent3.csv')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Closeness\n",
    "\n",
    "import random as rn\n",
    "import fiona\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint as rint\n",
    "import networkx as nx\n",
    "import functools\n",
    "from collections import deque\n",
    "from heapq import heappush, heappop\n",
    "from itertools import count\n",
    "import networkx as nx\n",
    "from networkx.utils import generate_unique_node\n",
    "\n",
    "\n",
    "def dist(i,j):\n",
    "    return np.sqrt( (i[0] - j[0])**2 + (i[1] - j[1])**2 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fp = fiona.open(\"/home/dario/trafico/redCDMX/VialidadOSM.shp\")\n",
    "calles = {}\n",
    "siq  = [u'highway', u'barrier', u'id', u'nombre', u'osm_id', u'other_tags', u'sentido', u'tipo', u'z_order']\n",
    "for feat in fp:\n",
    "    calles[ feat['id'] ] = {}\n",
    "    calles[ feat['id'] ]['type'] = feat['geometry']['type']\n",
    "    calles[ feat['id'] ]['coords'] = feat['geometry']['coordinates']\n",
    "    for key, val in feat['properties'].items():\n",
    "        if key in siq:\n",
    "            calles[ feat['id'] ][key] = val\n",
    "            calles[ feat['id'] ][key] = val\n",
    "\n",
    "\n",
    "fp.close()\n",
    "\n",
    "ntwk = pd.DataFrame(calles).transpose()\n",
    "ntwk.index = ntwk['id']\n",
    "ntwk = ntwk.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "i=0\n",
    "GN = nx.DiGraph(weighted=True)\n",
    "for row, col in ntwk.iterrows():\n",
    "    p = ntwk.loc[row]['coords']\n",
    "    lp = len(p)\n",
    "    GN.add_path( p, name=ntwk.loc[row]['nombre'],\n",
    "                vialidad = ntwk.loc[row]['highway'], osm_id = ntwk.loc[row]['osm_id'],\n",
    "                sentido = ntwk.loc[row]['sentido'], tipo=ntwk.loc[row]['tipo']\n",
    "               )\n",
    "    i = lp + i\n",
    "    \n",
    "    \n",
    "gnfc = sorted(nx.strongly_connected_components(GN), key = len, reverse=True)[0]\n",
    "gfc = GN.subgraph(gnfc)\n",
    "\n",
    "for edge in gfc.edges():\n",
    "    gfc[edge[0]][edge[1]]['dist'] = dist(*edge)\n",
    "\n",
    "\n",
    "\n",
    "def _dijkstra(G, source, get_weight, pred=None, paths=None, cutoff=None,\n",
    "              target=None):\n",
    "    G_succ = G.succ if G.is_directed() else G.adj\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    dist = {}  # dictionary of final distances\n",
    "    seen = {source: 0}\n",
    "    c = count()\n",
    "    fringe = []  # use heapq with (distance,label) tuples\n",
    "    push(fringe, (0, next(c), source))\n",
    "    while fringe:\n",
    "        (d, _, v) = pop(fringe)\n",
    "        if v in dist:\n",
    "            continue  # already searched this node.\n",
    "        dist[v] = d\n",
    "        if v == target:\n",
    "            break\n",
    "        for u, e in G_succ[v].items():\n",
    "            cost = get_weight(v, u, e)\n",
    "            if cost is None:\n",
    "                continue\n",
    "            vu_dist = dist[v] + get_weight(v, u, e)\n",
    "            if cutoff is not None:\n",
    "                if vu_dist > cutoff:\n",
    "                    continue\n",
    "            if u in dist:\n",
    "                if vu_dist < dist[u]:\n",
    "                    raise ValueError('Contradictory paths found:',\n",
    "                                     'negative weights?')\n",
    "            elif u not in seen or vu_dist < seen[u]:\n",
    "                seen[u] = vu_dist\n",
    "                push(fringe, (vu_dist, next(c), u))\n",
    "                if paths is not None:\n",
    "                    paths[u] = paths[v] + [u]\n",
    "                if pred is not None:\n",
    "                    pred[u] = [v]\n",
    "            elif vu_dist == seen[u]:\n",
    "                if pred is not None:\n",
    "                    pred[u].append(v)\n",
    "\n",
    "    if paths is not None:\n",
    "        return (dist, paths)\n",
    "    if pred is not None:\n",
    "        return (pred, dist)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def single_source_dijkstra_path_length_g(G, source, target, cutoff=None,\n",
    "                                       weight='weight'):\n",
    "    if G.is_multigraph():\n",
    "        get_weight = lambda u, v, data: min(\n",
    "            eattr.get(weight, 1) for eattr in data.values())\n",
    "    else:\n",
    "        get_weight = lambda u, v, data: data.get(weight, 1)\n",
    "\n",
    "    return _dijkstra(G, source, get_weight, cutoff=cutoff, target=target)\n",
    "\n",
    "\n",
    "def clos_cen(G, u=None, distance=None, normalized=True):\n",
    "    if distance is not None:\n",
    "        # use Dijkstra's algorithm with specified attribute as edge weight \n",
    "        path_length = functools.partial(single_source_dijkstra_path_length_g,\n",
    "                                        weight=distance)\n",
    "    else:\n",
    "        path_length = nx.single_source_shortest_path_length\n",
    "    if u is None:\n",
    "        nodes = [x for x in G.nodes() if nx.degree(G, x) > 3 ]\n",
    "    else:\n",
    "        nodes = [u]\n",
    "    closeness_centrality = {}\n",
    "    for n in nodes[len(nodes)/2:]:\n",
    "        sp = path_length(G,n, target=nodes)\n",
    "        totsp = sum(sp.values())\n",
    "        if totsp > 0.0 and len(G) > 1:\n",
    "            closeness_centrality[n] = (len(sp)-1.0) / totsp\n",
    "            # normalize to number of nodes-1 in connected part\n",
    "            if normalized:\n",
    "                s = (len(sp)-1.0) / ( len(G) - 1 )\n",
    "                closeness_centrality[n] *= s\n",
    "        else:\n",
    "            closeness_centrality[n] = 0.0\n",
    "    if u is not None:\n",
    "        return closeness_centrality[u]\n",
    "    else:\n",
    "        return closeness_centrality    \n",
    "    \n",
    "    \n",
    "dcc = clos_cen(gfc, u=None, distance='dist')\n",
    "\n",
    "import pickle\n",
    "with open('dic_clos_cent3b.py', 'wb') as fp:\n",
    "    pickle.dump(dcc, fp)\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.DataFrame(dcc)\n",
    "    df.to_csv('dic_clos_cent3b.csv')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Closeness\n",
    "\n",
    "import random as rn\n",
    "import fiona\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint as rint\n",
    "import networkx as nx\n",
    "import functools\n",
    "\n",
    "def dist(i,j):\n",
    "    return np.sqrt( (i[0] - j[0])**2 + (i[1] - j[1])**2 )\n",
    "\n",
    "\n",
    "\n",
    "fp = fiona.open(\"/home/dario/trafico/redCDMX/VialidadOSM.shp\")\n",
    "calles = {}\n",
    "siq  = [u'highway', u'barrier', u'id', u'nombre', u'osm_id', u'other_tags', u'sentido', u'tipo', u'z_order']\n",
    "for feat in fp:\n",
    "    calles[ feat['id'] ] = {}\n",
    "    calles[ feat['id'] ]['type'] = feat['geometry']['type']\n",
    "    calles[ feat['id'] ]['coords'] = feat['geometry']['coordinates']\n",
    "    for key, val in feat['properties'].items():\n",
    "        if key in siq:\n",
    "            calles[ feat['id'] ][key] = val\n",
    "            calles[ feat['id'] ][key] = val\n",
    "\n",
    "\n",
    "fp.close()\n",
    "\n",
    "ntwk = pd.DataFrame(calles).transpose()\n",
    "ntwk.index = ntwk['id']\n",
    "ntwk = ntwk.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "i=0\n",
    "GN = nx.DiGraph(weighted=True)\n",
    "for row, col in ntwk.iterrows():\n",
    "    p = ntwk.loc[row]['coords']\n",
    "    lp = len(p)\n",
    "    GN.add_path( p, name=ntwk.loc[row]['nombre'],\n",
    "                vialidad = ntwk.loc[row]['highway'], osm_id = ntwk.loc[row]['osm_id'],\n",
    "                sentido = ntwk.loc[row]['sentido'], tipo=ntwk.loc[row]['tipo']\n",
    "               )\n",
    "    i = lp + i\n",
    "    \n",
    "    \n",
    "gnfc = sorted(nx.strongly_connected_components(GN), key = len, reverse=True)[0]\n",
    "gfc = GN.subgraph(gnfc)\n",
    "\n",
    "for edge in gfc.edges():\n",
    "    gfc[edge[0]][edge[1]]['dist'] = dist(*edge)\n",
    "\n",
    "\n",
    "\n",
    "def clos_cen(G, u=None, distance=None, normalized=True):\n",
    "    if distance is not None:\n",
    "        # use Dijkstra's algorithm with specified attribute as edge weight \n",
    "        path_length = functools.partial(nx.single_source_dijkstra_path_length,\n",
    "                                        weight=distance)\n",
    "    else:\n",
    "        path_length = nx.single_source_shortest_path_length\n",
    "\n",
    "    if u is None:\n",
    "        nodes = [x for x in G.nodes() if nx.degree(G, x) > 3 ]\n",
    "    else:\n",
    "        nodes = [u]\n",
    "    closeness_centrality = {}\n",
    "    for n in nodes:\n",
    "        sp = path_length(G,n)\n",
    "        totsp = sum(sp.values())\n",
    "        if totsp > 0.0 and len(G) > 1:\n",
    "            closeness_centrality[n] = (len(sp)-1.0) / totsp\n",
    "            # normalize to number of nodes-1 in connected part\n",
    "            if normalized:\n",
    "                s = (len(sp)-1.0) / ( len(G) - 1 )\n",
    "                closeness_centrality[n] *= s\n",
    "        else:\n",
    "            closeness_centrality[n] = 0.0\n",
    "    if u is not None:\n",
    "        return closeness_centrality[u]\n",
    "    else:\n",
    "        return closeness_centrality    \n",
    "    \n",
    "    \n",
    "dcc = clos_cen(gfc, u=None, distance='dist')\n",
    "\n",
    "import pickle\n",
    "with open('dic_clos_cent2.py', 'wb') as fp:\n",
    "    pickle.dump(dcc, fp)\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.DataFrame(dcc)\n",
    "    df.to_csv('dic_clos_cent2.csv')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### ECCENTRICITY\n",
    "\n",
    "import random as rn\n",
    "import fiona\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint as rint\n",
    "import networkx as nx\n",
    "import functools\n",
    "\n",
    "def dist(i,j):\n",
    "    return np.sqrt( (i[0] - j[0])**2 + (i[1] - j[1])**2 )\n",
    "\n",
    "\n",
    "\n",
    "fp = fiona.open(\"/home/dario/trafico/redCDMX/VialidadOSM.shp\")\n",
    "calles = {}\n",
    "siq  = [u'highway', u'barrier', u'id', u'nombre', u'osm_id', u'other_tags', u'sentido', u'tipo', u'z_order']\n",
    "for feat in fp:\n",
    "    calles[ feat['id'] ] = {}\n",
    "    calles[ feat['id'] ]['type'] = feat['geometry']['type']\n",
    "    calles[ feat['id'] ]['coords'] = feat['geometry']['coordinates']\n",
    "    for key, val in feat['properties'].items():\n",
    "        if key in siq:\n",
    "            calles[ feat['id'] ][key] = val\n",
    "            calles[ feat['id'] ][key] = val\n",
    "\n",
    "\n",
    "fp.close()\n",
    "\n",
    "ntwk = pd.DataFrame(calles).transpose()\n",
    "ntwk.index = ntwk['id']\n",
    "ntwk = ntwk.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "i=0\n",
    "GN = nx.DiGraph(weighted=True)\n",
    "for row, col in ntwk.iterrows():\n",
    "    p = ntwk.loc[row]['coords']\n",
    "    lp = len(p)\n",
    "    GN.add_path( p, name=ntwk.loc[row]['nombre'],\n",
    "                vialidad = ntwk.loc[row]['highway'], osm_id = ntwk.loc[row]['osm_id'],\n",
    "                sentido = ntwk.loc[row]['sentido'], tipo=ntwk.loc[row]['tipo']\n",
    "               )\n",
    "    i = lp + i\n",
    "    \n",
    "    \n",
    "gnfc = sorted(nx.strongly_connected_components(GN), key = len, reverse=True)[0]\n",
    "gfc = GN.subgraph(gnfc)\n",
    "\n",
    "for edge in gfc.edges():\n",
    "    gfc[edge[0]][edge[1]]['dist'] = dist(*edge)\n",
    "\n",
    "\n",
    "\n",
    "def eccen(G, v=None, distance=None,):\n",
    "    order=G.order()\n",
    "    e={}\n",
    "    nodes = [x for x in G.nodes() if nx.degree(G, x) > 3 ]\n",
    "    #for n in G.nbunch_iter(v):\n",
    "    for n in nodes[:len(nodes)/2]:\n",
    "        path_length = functools.partial(nx.single_source_dijkstra_path_length,weight=distance)\n",
    "        length = path_length(G,n)    \n",
    "        e[n]=max(length.values())\n",
    "    if v in G:\n",
    "        return e[v]  # return single value\n",
    "    else:\n",
    "        return e\n",
    "\n",
    "\n",
    "decc = eccen(gfc, u=None, distance='dist')\n",
    "\n",
    "import pickle\n",
    "with open('dic_eccen_2.py', 'wb') as fp:\n",
    "    pickle.dump(decc, fp)\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.DataFrame(dcc)\n",
    "    df.to_csv('dic_eccen_2.csv')\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 8.1",
   "language": "",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
